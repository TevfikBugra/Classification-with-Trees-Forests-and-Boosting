# Classification-with-Trees-Forests-and-Boosting
**Objective**: This project aims to classify outcomes for a banking dataset and predict bike rental counts in Seoul using advanced tree-based machine learning techniques. By employing `decision trees`, `random forests`, and `gradient boosting machines`, the goal is to achieve high accuracy and robust predictions.

### Methodology:

**Data Partitioning**: The datasets are split into training and test sets, ensuring reliable evaluation of model performance.

**Tree-Based Methods**: We implemented decision trees, random forests, and gradient boosting algorithms. These methods were applied to both classification and regression tasks.

**Parameter Optimization**: Extensive parameter tuning was conducted to optimize model performance, focusing on key parameters such as mtry, ntree, interaction.depth, n.trees, and shrinkage.

**Evaluation**: The models were evaluated using cross-validation and performance metrics such as RMSE, accuracy, sensitivity, and specificity.

**Programming Language**: R

**Summary**: This project showcases proficiency in R, data mining, and machine learning by effectively utilizing tree-based methods to classify and predict outcomes. The implementation of decision trees, random forests, and gradient boosting machines highlights a strong understanding of model optimization and evaluation techniques. This approach demonstrates the capability to analyze and interpret complex datasets, making data-driven decisions to improve model accuracy.

**Additional Contributors**: Ömercan Mısırlıoğlu
